{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "The task that have to be done corresponds to finding groups of similar products/items, which are dissimilar to each other.\n",
    "\n",
    "In **Part1**, the similarity matrix was computed. Some of the clustering algorithms require instead the distance matrix. However, this is not a problem, since the distance matrix can be easily obtained as: `dmatrix = 1-smatrix`.\n",
    "\n",
    "In what follows, 3 clustering algorithms are tested: DBSCAN and Spectral Clustering. Both methods were chosen because for their ability to find clusters of irregular shapes, which probably is the case in our problem (It is not possible visualize it either).\n",
    "\n",
    "\n",
    "#### Evaluation\n",
    "In order to evaluate the results from the different clustering algorithms tested, the silhouette metric is used. Silhouette Coefficient is calculated using the mean intra-cluster distance `a` and the mean nearest-cluster distance (b) for each sample. The Silhouette Coefficient for a sample is `(b - a) / max(a, b)`.\n",
    "\n",
    "The best value is `1` and the worst value is `-1`. Values near `0` indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smatrix = np.load(\"data/smatrix.npy\")\n",
    "dmatrix = 1-smatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN\n",
    "\n",
    "DBSCAN is a clustering algorithm based on the density of distribution of the data samples. DBSCAN captures the insight that clusters are dense groups of points. The idea is that if a particular point belongs to a cluster, it should be near to lots of other points in that cluster. \n",
    "\n",
    "Below DBSCAN is tested with different values of `eps`, which is the radio of neighborhood the algorithm searches for new neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/cluster/unsupervised.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sil_samples /= np.maximum(intra_clust_dists, inter_clust_dists)\n",
      "/Users/martin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/cluster/unsupervised.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sil_samples /= np.maximum(intra_clust_dists, inter_clust_dists)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best silhouette score:  0.09569720215997334\n",
      "Number of clusters: 3\n",
      "Predictions: [ 0  0  0 ... -1 -1 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/cluster/unsupervised.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sil_samples /= np.maximum(intra_clust_dists, inter_clust_dists)\n"
     ]
    }
   ],
   "source": [
    "eps_list = np.linspace(0., 0.1, 26)[1:]\n",
    "best_clf = None\n",
    "best_pred = None\n",
    "best_score = -1\n",
    "\n",
    "for eps in eps_list:\n",
    "    clf = DBSCAN(metric=\"precomputed\", n_jobs=2, eps=eps)\n",
    "    pred = clf.fit_predict(dmatrix)\n",
    "    score = silhouette_score(dmatrix, pred, metric=\"precomputed\")\n",
    "    if score>best_score:\n",
    "        best_score = score\n",
    "        best_clf = clf\n",
    "        best_pred = pred\n",
    "\n",
    "print(\"Best silhouette score: \",best_score)\n",
    "print(\"Number of clusters:\", np.max(best_pred)+1)\n",
    "print(\"Predictions:\",best_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Clustering\n",
    "\n",
    "Spectral clustering techniques make use of the spectrum (eigenvalues) of the similarity matrix of the data to perform dimensionality reduction before clustering in fewer dimensions.\n",
    "\n",
    "Spectral Clustering is very useful when the structure of the individual clusters is highly non-convex or more generally when a measure of the center and spread of the cluster is not a suitable description of the complete cluster (**which is clearly our case**).\n",
    "\n",
    "Below Spectral Clustering is tested with different values of `n_clusters`, which is the radio of neighborhood the algorithm searches for new neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/martin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:709: UserWarning: Array is not symmetric, and will be converted to symmetric by average with its transpose.\n",
      "  warnings.warn(\"Array is not symmetric, and will be converted \"\n",
      "/Users/martin/anaconda3/lib/python3.6/site-packages/sklearn/metrics/cluster/unsupervised.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sil_samples /= np.maximum(intra_clust_dists, inter_clust_dists)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best silhouette score:  0.17174173898115225\n",
      "Number of clusters: 2\n",
      "Predictions: [1 1 1 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "n_clusters_list = np.arange(2,21)\n",
    "best_clf = None\n",
    "best_pred = None\n",
    "best_score = -1\n",
    "\n",
    "for n_cluster in n_clusters_list:\n",
    "    clf = SpectralClustering(n_clusters=n_cluster, affinity=\"precomputed\", n_jobs=2)\n",
    "    pred = clf.fit_predict(smatrix)\n",
    "    score = silhouette_score(dmatrix, pred, metric=\"precomputed\")\n",
    "    if score>best_score:\n",
    "        best_score = score\n",
    "        best_clf = clf\n",
    "        best_pred = pred\n",
    "\n",
    "print(\"Best silhouette score: \",best_score)\n",
    "print(\"Number of clusters:\", np.max(best_pred)+1)\n",
    "print(\"Predictions:\",best_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Neither of the two methods achieved a great silhouette score, however Spectral Clustering with `n_cluster=2` was the best algorithm configuration. Therefore, this was setting for the `get_cluster.py` script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
